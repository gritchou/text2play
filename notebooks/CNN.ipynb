{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def style_transfer(content_img_path, style_img_path, stylized_name, num_steps=300, content_weight=1e5, style_weight=1e10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Function to load an image from the path and prepare it for processing\n",
    "    def load_image(img_path, size=512, scale=None):\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if scale:\n",
    "            size = int(scale * min(image.size))\n",
    "        loader = transforms.Compose([\n",
    "            transforms.Resize((size, size)),  # scale imported image\n",
    "            transforms.ToTensor(),  # transform it into a torch tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = loader(image).unsqueeze(0)\n",
    "        return image.to(device, torch.float)\n",
    "\n",
    "    # Load content and style images\n",
    "    content_img = load_image(content_img_path)\n",
    "    style_img = load_image(style_img_path, scale=0.5)\n",
    "\n",
    "    # Load the pre-trained VGG19 model\n",
    "    vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features\n",
    "    for param in vgg.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Move the model to GPU, if available\n",
    "    vgg.to(device)\n",
    "\n",
    "    # Function to extract features from the layers\n",
    "    def get_features(image, model, layers=None):\n",
    "        if layers is None:\n",
    "            layers = {'0': 'conv1_1', '5': 'conv2_1', '10': 'conv3_1', '19': 'conv4_1', '21': 'conv4_2', '28': 'conv5_1'}\n",
    "        features = {}\n",
    "        x = image\n",
    "        for name, layer in model._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in layers:\n",
    "                features[layers[name]] = x\n",
    "        return features\n",
    "\n",
    "    # Function to calculate the Gram matrix of an image\n",
    "    def gram_matrix(tensor):\n",
    "        _, d, h, w = tensor.size()\n",
    "        tensor = tensor.view(d, h * w)\n",
    "        gram = torch.mm(tensor, tensor.t())\n",
    "        return gram\n",
    "\n",
    "    # Get content and style features only once before forming the target image\n",
    "    content_features = get_features(content_img, vgg)\n",
    "    style_features = get_features(style_img, vgg)\n",
    "    style_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}\n",
    "\n",
    "    # Create a 'target' image and clone the content image\n",
    "    target = content_img.clone().requires_grad_(True).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam([target], lr=0.003)\n",
    "\n",
    "    # Style transfer process\n",
    "    for i in range(1, num_steps + 1):\n",
    "        target_features = get_features(target, vgg)\n",
    "        content_loss = torch.mean((target_features['conv4_2'] - content_features['conv4_2'])**2)\n",
    "\n",
    "        style_loss = 0\n",
    "        for layer in style_grams:\n",
    "            target_feature = target_features[layer]\n",
    "            target_gram = gram_matrix(target_feature)\n",
    "            _, d, h, w = target_feature.shape\n",
    "            style_gram = style_grams[layer]\n",
    "            layer_style_loss = torch.mean((target_gram - style_gram)**2)\n",
    "            style_loss += layer_style_loss / (d * h * w)\n",
    "\n",
    "        total_loss = content_weight * content_loss + style_weight * style_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Step {}, Total loss: {}'.format(i, total_loss.item()))\n",
    "\n",
    "    # Convert the tensor image to PIL image for saving\n",
    "    unloader = transforms.ToPILImage()\n",
    "    final_img = target.cpu().clone().squeeze(0)\n",
    "    final_img = unloader(final_img)\n",
    "\n",
    "    save_image(final_img, stylized_name)\n",
    "\n",
    "    return final_img\n",
    "\n",
    "# Use the function\n",
    "final_img = style_transfer('raw_data/images/content/astronaut.png', 'raw_data/images/style/The_Scream_S.jpg', 'raw_data/images/stylized/astronaut_stylized.jpg')\n",
    "final_img.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
